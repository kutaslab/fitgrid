{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# NOAA tides and weather epochs\n\nThis example wrangles about 10 years of somewhat messy hourly NOAA\n`meteorological observations \n<https://tidesandcurrents.noaa.gov/met.html?id=9410230&units=standard&timezone=GMT&action=data>`_\nand `water levels\n<https://tidesandcurrents.noaa.gov/waterlevels.html?id=9410230&units=standard&timezone=GMT&action=data>`_\ninto tidy `pandas.DataFrame` of time-stamped epochs ready to\nload as `fitgrid.Epochs` for modeling.\n \n1. Groom separate NOAA ocean water level and atmospheric observation\ndata files and merge into a single time-stamped `pandas.DataFrame`.\n\n2. Add a column of event tags that mark the `high_tide` time-locking events of interest.\n\n3. Snip the time-series apart into fixed length epochs and construct a\nnew column of time-stamps in each epoch with the `high_tide` event of\ninterest at time=0.\n\n4. Export the epochs data frame to save for later use in `fitgrid`\n\nData Source: \n\n| NOAA CO-OPS-9419230  \n| Station: La Jolla, CA 94102 (Scripps Pier)   \n| August 1, 2010 - July 1, 2020  \n\nThe water levels are measured relative to mean sea level (MSL). For\nfurther information about these data see `tide data options\n<https://tidesandcurrents.noaa.gov/datum_options.html>`_, the\nComputational Technniques for Tidal Datums Handbook [NOS-CO-OPS2]_\nand the `NOAA Glossary\n<https://tidesandcurrents.noaa.gov/glossary.html>`_.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport fitgrid as fg\nfrom fitgrid import DATA_DIR\n\nplt.style.use(\"seaborn-bright\")\nrc_colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n\nnp.random.seed(512)\n\n# path to hourly water level and meteorology data\nWDIR = DATA_DIR / \"CO-OPS_9410230\"\n\nfor pkg in [fg, np, pd]:\n    print(pkg.__name__, pkg.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean and merge tide and weather data\n\nThe `tides` variable is the hourly water level measurements. The\noriginal `date` and `time_(gmt)` columns are converted to a\n`pandas.Datetime` and serve as the index for merging the water level\ndata with the meteorological observations.  Missing observations are coded `NaN`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# read and tidy the NOAA water level .csv data files\ntides = pd.concat(\n    [pd.read_csv(tide_f, na_values='-') for tide_f in WDIR.glob('*msl_wl.csv')]\n).drop([\"Predicted (ft)\", \"Preliminary (ft)\"], axis=1)\n\n# sanitize the column names\ntides.columns = [col.lower().replace(\" \", \"_\") for col in tides.columns]\n\n# make gmt date times usable\ntides['date_time_gmt'] = pd.to_datetime(\n    tides['date'] + ' ' + tides[\"time_(gmt)\"]\n)\n\n# add local time at Scripps from the GMT\ntides.insert(\n    1,\n    'hour_pst',\n    (tides['date_time_gmt'] + pd.Timedelta(hours=-8)).dt.time.astype(str),\n)\n\n# drop unused columns\ntides = tides.sort_values('date_time_gmt').drop(['date', 'time_(gmt)'], axis=1)\n\ntides.rename(columns={\"verified_(ft)\": \"water_level\"}, inplace=True)\n\ntides.set_index(\"date_time_gmt\", inplace=True)\nprint(tides)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`metobs` are hourly meteorological observations from the same NOAA station.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "metobs = pd.concat(\n    [pd.read_csv(tide_f, na_values='-') for tide_f in WDIR.glob('*met.csv')]\n)\nmetobs.columns = [\n    col.strip().lower().replace(\" \", \"_\") for col in metobs.columns\n]\nmetobs['date_time_gmt'] = pd.to_datetime(metobs.date_time)\nmetobs = metobs.drop(\n    [\"windspeed\", \"dir\", \"gusts\", \"relhum\", \"vis\", \"date_time\"], axis=1\n)[[\"date_time_gmt\", \"baro\", \"at\"]]\n\nmetobs.set_index(\"date_time_gmt\", inplace=True)\nmetobs.rename(columns={\"baro\": \"mm_hg\", \"at\": \"air_temp\"}, inplace=True)\n\nprint(metobs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `data` pandas.DataFrame has the time-aligned tide and\natmospheric observations, merged on their datetime stamp. Missing\ndata `NaN` in either set of observations triggers exclusion of the\nentire row.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = tides.join(metobs, on='date_time_gmt').dropna().reset_index()\n\n# standardize the observations\nfor col in [\"water_level\", \"mm_hg\", \"air_temp\"]:\n    data[col + \"_z\"] = (data[col] - data[col].mean()) / data[col].std()\n\n# add a column of standard normal random values for comparison\ndata[\"std_noise_z\"] = np.random.normal(loc=-0, scale=1.0, size=len(data))\nprint(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## set time=0 at high tide\n\nThe fixed length \"epochs\" are defined as intervals around the time=0\n\"time-locking\" event at `high_tide` defined by the local\nwater-level maximum. Other time-lock events could be imagined:\nlow-tide, high-to-low zero crossing etc.. Note that there are two\nhigh-tide events in each approximately 24 hour period.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# boolean vector True at water level local maxima , i.e., high tide\ndata['high_tide'] = (\n    np.r_[\n        False,\n        data.water_level_z[1:].to_numpy() > data.water_level_z[:-1].to_numpy(),\n    ]\n    & np.r_[\n        data.water_level_z[:-1].to_numpy() > data.water_level_z[1:].to_numpy(),\n        False,\n    ]\n)\n\n# these are just the high tide rows\nprint(data[data['high_tide'] == True])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the epoch parameters: fixed-length duration, time-stamps, and epoch index.\n\nIn this example, the epoch duration is 11 hours, beginning 3 hours before the high tides time lock event at time stamp = 0.\n\n1. Fixed-length duration. This is the same for all epochs\n   in the data. In this example, the epoch is 11 hours, i.e., 11 measurements.#\n\n2. Time stamps. This is an increasing sequence of integers, the same\n   length as the epoch. In this example the data are time-stamped\n   relative to high-tide at time=0, i.e., $-3, -2, -1, 0, 1,\n   2, 3, 4, 5, 6, 7,$.\n\n3. Assign each epoch an integer index that uniquely identifies\n   it. The indexes can be gappy but there can be no duplicates. In this\n   example the epoch index is a simple counter from 0 to the number of epochs - 1.\n\n\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# 1. duration defined by the interval before and after the time lock event\npre, post = 3, 8\n\n# 2. sequential time stamps\nhrs = list(range(0 - pre, post))\n\n# 3. epoch index is a counter for the high tide events.\nn_obs = len(data)\nht_idxs = np.where(data.high_tide)[0]\n\n# pre-compute epoch slice boundaries ... note these start-stop\n# intervals may overlap in the original data\nepoch_bounds = [\n    (ht_idx - pre, ht_idx + post)\n    for ht_idx in ht_idxs\n    if ht_idx >= pre and ht_idx + post < n_obs\n]\n\nepochs = []\nfor start, stop in epoch_bounds:\n    epoch = data.iloc[\n        start:stop, :\n    ].copy()  # slice the epoch interval from the original data\n    epoch['epoch_id'] = len(epochs)  # construct\n    epoch['time'] = hrs\n    epochs.append(epoch)\n\nepochs_df = pd.concat(epochs).set_index(['epoch_id', 'time'])\nepochs_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualize the epochs\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dt_start, dt_stop = '2011-08-01', '2011-08-06 22:00:00'\naug_01_07_11 = data.query(\n    \"date_time_gmt >= @dt_start and date_time_gmt < @dt_stop\"\n)\nprint(aug_01_07_11)\n\nf, ax = plt.subplots(figsize=(12, 8))\nax.set(ylim=(-3, 3))\nax.plot(\n    aug_01_07_11.date_time_gmt,\n    aug_01_07_11.water_level_z,\n    lw=2,\n    alpha=0.25,\n    ls='-',\n    marker='.',\n    markersize=10,\n    color='blue',\n)\n\nax.plot(\n    aug_01_07_11.date_time_gmt,\n    aug_01_07_11.water_level_z,\n    marker='.',\n    markersize=10,\n    lw=0,\n)\n\nax.scatter(\n    aug_01_07_11.date_time_gmt[aug_01_07_11.high_tide == True],\n    aug_01_07_11.water_level_z[aug_01_07_11.high_tide == True],\n    color='red',\n    s=100,\n    zorder=3,\n    label=\"high tide\",\n)\n\nfor day, (_, ht) in enumerate(\n    aug_01_07_11[aug_01_07_11.high_tide == True].iterrows()\n):\n    txt = ax.annotate(\n        str(ht.hour_pst),\n        (ht.date_time_gmt, ht.water_level_z),\n        (ht.date_time_gmt, ht.water_level_z * 1.02),\n        ha='left',\n        va='bottom',\n        fontsize=8,\n        rotation=30,\n    )\n    if day in [3, 4, 5]:\n        ax.axvline(ht.date_time_gmt, color='black', ls=\"--\")\n        ax.axvspan(\n            ht.date_time_gmt - pd.Timedelta(pre, 'h'),\n            ht.date_time_gmt + pd.Timedelta(post, 'h'),\n            color='magenta',\n            alpha=0.1,\n        )\n        if day == 5:\n            ax.annotate(\n                xy=(ht.date_time_gmt + pd.Timedelta(hours=1), 2.0),\n                s=(\n                    \"Highlight indicates epoch bounds. Overlapping epochs\\n\"\n                    \"are legal but the observations are duplicated. This\\n\"\n                    \"will increase the epochs data size and may violate\\n\"\n                    \"modeling assumptions. This is not checked.\"\n                ),\n                size=12,\n            )\n\n\nax.set_title(\n    f\"One week of standardized hourly water levels {dt_start} - {dt_stop} at La Jolla, CA \"\n)\nax.legend()\nf.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The tidied fixed-length, time-stamped epochs data may be saved for re-use as data tables.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# export time-stamped epochs for loading into fitgrid.Epochs\nepochs_df.reset_index().to_feather(DATA_DIR / \"CO-OPS_9410230.feather\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}