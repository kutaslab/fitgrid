{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pprint as pp\n",
    "import numpy as np\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import statsmodels.regression as smreg\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from patsy import dmatrices, dmatrix, demo_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun with numpy.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3,)\n",
      "(3,)\n",
      "()\n",
      "()\n",
      "()\n",
      "(1, 1)\n",
      "(1,)\n",
      "()\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "# scalar and subarray dtypes \n",
    "one_x_one_shape_dt = np.dtype([('my_sing_type', 'f8', (1,1))]) # 2-D subarray 1 row, 1 col\n",
    "singleton_shape_dt = np.dtype([('my_sing_type', 'f8', (1,))])  # 1-D subarray 1 row\n",
    "no_shape_dt = np.dtype([('my_type', 'f8')]) # 0-D i.e., no subarray, i.e., scalar\n",
    "\n",
    "arry_a = np.ndarray(shape=(3,), dtype = one_x_one_shape_dt)\n",
    "arry_b = np.ndarray(shape=(3,), dtype = singleton_shape_dt)\n",
    "arry_c = np.ndarray(shape=(3,), dtype = no_shape_dt)\n",
    "\n",
    "print(arry_a.shape) # (3,)\n",
    "print(arry_b.shape) # (3,)\n",
    "print(arry_c.shape) # (3)\n",
    "\n",
    "print(arry_a[0].shape) \n",
    "print(arry_b[0].shape)\n",
    "print(arry_c[0].shape)\n",
    "\n",
    "print(arry_a[0][0].shape)\n",
    "print(arry_b[0][0].shape)\n",
    "print(arry_c[0][0].shape)\n",
    "\n",
    "print(arry_a[0][0].__class__) # shape (1,1) gives ndarray\n",
    "print(arry_b[0][0].__class__) # shape (1,) gives ndarray\n",
    "print(arry_c[0][0].__class__) # shape () gives float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1\n",
      "[[ 1.  1.  1.]\n",
      " [ 2.  2.  2.]\n",
      " [ 3.  3.  3.]\n",
      " [ 4.  4.  4.]\n",
      " [ 5.  5.  5.]]\n",
      "test2\n",
      "[[['A_1_1' 'A_1_1']\n",
      "  ['B_1_2' 'B_1_2']\n",
      "  ['C_1_3' 'C_1_3']]\n",
      "\n",
      " [['A_2_1' 'A_2_1']\n",
      "  ['B_2_2' 'B_2_2']\n",
      "  ['C_2_3' 'C_2_3']]\n",
      "\n",
      " [['A_3_1' 'A_3_1']\n",
      "  ['B_3_2' 'B_3_2']\n",
      "  ['C_3_3' 'C_3_3']]\n",
      "\n",
      " [['A_4_1' 'A_4_1']\n",
      "  ['B_4_2' 'B_4_2']\n",
      "  ['C_4_3' 'C_4_3']]\n",
      "\n",
      " [['A_5_1' 'A_5_1']\n",
      "  ['B_5_2' 'B_5_2']\n",
      "  ['C_5_3' 'C_5_3']]]\n",
      "2nd row slice through both arrays\n",
      "([2.0, 2.0, 2.0], [['A_2_1', 'A_2_1'], ['B_2_2', 'B_2_2'], ['C_2_3', 'C_2_3']])\n"
     ]
    }
   ],
   "source": [
    "dt_names = ['test1', 'test2']\n",
    "dt_formats = [ ('f8', (3,)), ('U8', (3,2))]\n",
    "\n",
    "# dict pattern\n",
    "test_type = np.dtype({\n",
    "        'names': dt_names,\n",
    "        'formats': dt_formats\n",
    "})\n",
    "\n",
    "n = 5\n",
    "mydat = np.empty(shape=(n,), dtype=test_type)\n",
    "for i in range(n):\n",
    "    mydat['test1'][i].fill(i+1)\n",
    "    for ij, al in enumerate(['A','B','C']):\n",
    "        mydat['test2'][i][ij] = al + '_' + str(i+1) + '_' + str(ij+1)\n",
    "\n",
    "print('test1')\n",
    "print(mydat['test1'])\n",
    "\n",
    "print('test2')\n",
    "print(mydat['test2'])\n",
    "\n",
    "# looks like we can slice the middle row *across* different shape subarrays. cool.\n",
    "print('2nd row slice through both arrays')\n",
    "pp.pprint(mydat[...][1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to fit bucket dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Intercept', 'a[T.a2]', 'x0', 'x1']\n",
      "OrderedDict([('Intercept', 0), ('a[T.a2]', 1), ('x0', 2), ('x1', 3)])\n"
     ]
    }
   ],
   "source": [
    "# demo data from patsy\n",
    "data = demo_data('y', 'a', 'x0','x1')\n",
    "\n",
    "# patsy can tell us about the rhs design matrix\n",
    "lhs = 'y'\n",
    "rhs = 'x0 + x1 + a'\n",
    "formula = lhs + '~' + rhs\n",
    "\n",
    "# to scrape the fit we want the names and number of the rhs terms\n",
    "rhs_dmat = dmatrix(rhs, data=data)\n",
    "rhs_di = rhs_dmat.design_info\n",
    "print(rhs_di.column_names)\n",
    "print(rhs_di.column_name_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make the ci interval a dtype of its own\n",
    "# and build it into the fit_coef_dt\n",
    "ci_dt = np.dtype([('lower', '<f8'), ('upper', '<f8')])\n",
    "\n",
    "# define the data type\n",
    "fit_coef_dt = np.dtype([('idx','<u8'),# rhs column index\n",
    "                         ('coef', '<f8',), # parameter estimate\n",
    "                         ('se','<f8',), # SE\n",
    "                         ('ci',ci_dt)]) # conf interval\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now consult the the model rhs design matrix and build the fit part of the\n",
    "# fit bucket dtype.\n",
    "\n",
    "# Option 1 is an 1-D ndarray shape=(1,) of a single compound data type\n",
    "# wrapped around all the parameter info. This allows key-value access\n",
    "# down into each parameter by name but no slicing across parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "('Intercept', 'a[T.a2]', 'x0', 'x1')\n",
      "[  2.34142453e-316]\n",
      "[(6.9155226262719e-310, 6.9155319292632e-310)]\n",
      "('no field of name coef',)\n"
     ]
    }
   ],
   "source": [
    "# Option 1: make one big master dtype for this rhs design matrix\n",
    "# and make the fit object a singleton array of this dtype\n",
    "\n",
    "# one big compound data type ... a different\n",
    "# dtype for different design matrices.\n",
    "fit_dt = np.dtype([(name,fit_coef_dt) \\\n",
    "                       for name in rhs_di.column_names])\n",
    "\n",
    "# the fit is an ndarray of 1 of these dtypes\n",
    "fit = np.empty(shape=(1,), dtype=fit_dt)\n",
    "print(fit.__class__)\n",
    "print(fit.dtype.names)\n",
    "\n",
    "# Advantages: access to parameter info by column name\n",
    "print(fit['Intercept']['coef'])\n",
    "print(fit['x0']['ci'])\n",
    "\n",
    "# Disadvantages: cannot slice *across* coefs to extract a named field.\n",
    "try:\n",
    "    fit[...]['coef']\n",
    "except Exception as fail:\n",
    "    print(fail.args)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Toy example: building up an (empty) fit grid with\n",
    "\n",
    "# one of these per channel and sample in the fit grid\n",
    "fit_bucket_dt = np.dtype([('fit', fit_dt),\n",
    "                          ('diag', 'O')]) # stub for diag\n",
    "\n",
    "n_chans  = 4\n",
    "n_points = 10\n",
    "fit_grid = np.ndarray(shape=(n_chans, n_points), \n",
    "                      dtype=fit_bucket_dt)\n",
    "\n",
    "def fill_fit_bucket(fit_bucket, fit):\n",
    "    for i,f in enumerate(fit_bucket['fit'].dtype.names):\n",
    "        # TO DO: scrape the values from fit into the fit_bucket here\n",
    "        pass\n",
    "\n",
    "this_fit = None\n",
    "for ch in [0]: #range(n_chans):\n",
    "    for pt in [0]: #range(n_points):\n",
    "        y_dat = data['y']\n",
    "        this_model = smreg.linear_model.OLS(data['y'], rhs_dmat)\n",
    "        this_fit = this_model.fit()\n",
    "        fill_fit_bucket(fit_grid[0,0],this_fit)\n",
    "\n",
    "\n",
    "# now we **can** slice into the fit_grid[chan_idx,timepoint_idx] and\n",
    "# access parameter information by name ...\n",
    "# \n",
    "# \n",
    "# Example: rERPs = ['coef'] field over time\n",
    "fit_grid[0,:]['fit']['Intercept']['coef']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRATCH WORK BELOW HERE ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# So far what gets scraped from the model fit object is hardcoded.\n",
    "\n",
    "# A more mature version would take a list of fit object attributes\n",
    "# and return a compound data type with the right number and type and shape \n",
    "# of slots, e.g., \n",
    "# \n",
    "# def get_coef_dt(model_fit_object, list_of_fit_values):\n",
    "#    ...\n",
    "#   return np.dtype(for_these_fit_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC0_se Series\n",
      "HC1_se Series\n",
      "HC2_se Series\n",
      "HC3_se Series\n",
      "aic float64\n",
      "bic float64\n",
      "bse Series\n",
      "centered_tss float64\n",
      "compare_f_test method\n",
      "compare_lm_test method\n",
      "compare_lr_test method\n",
      "condition_number float64\n",
      "conf_int method\n",
      "conf_int_el method\n",
      "cov_HC0 ndarray\n",
      "cov_HC1 ndarray\n",
      "cov_HC2 ndarray\n",
      "cov_HC3 ndarray\n",
      "cov_kwds dict\n",
      "cov_params method\n",
      "cov_type str\n",
      "df_model float\n",
      "df_resid float64\n",
      "eigenvals ndarray\n",
      "el_test method\n",
      "ess float64\n",
      "f_pvalue float64\n",
      "f_test method\n",
      "fittedvalues Series\n",
      "fvalue float64\n",
      "get_influence method\n",
      "get_prediction method\n",
      "get_robustcov_results method\n",
      "initialize method\n",
      "k_constant int\n",
      "llf float64\n",
      "load method\n",
      "model OLS\n",
      "mse_model float64\n",
      "mse_resid float64\n",
      "mse_total float64\n",
      "nobs float\n",
      "normalized_cov_params DataFrame\n",
      "outlier_test method\n",
      "params Series\n",
      "predict method\n",
      "pvalues Series\n",
      "remove_data method\n",
      "resid Series\n",
      "resid_pearson ndarray\n",
      "rsquared float64\n",
      "rsquared_adj float64\n",
      "save method\n",
      "scale float64\n",
      "ssr float64\n",
      "summary method\n",
      "summary2 method\n",
      "t_test method\n",
      "tvalues Series\n",
      "uncentered_tss float64\n",
      "use_t bool\n",
      "wald_test method\n",
      "wald_test_terms method\n",
      "wresid Series\n",
      "['DataFrame' 'OLS' 'Series' 'bool' 'dict' 'float' 'float64' 'int' 'method'\n",
      " 'ndarray' 'str']\n"
     ]
    }
   ],
   "source": [
    "# But. There are a bunch of different kinds of attributes in the fit object that\n",
    "# have to be handled case by case ... see below.\n",
    "\n",
    "# These are all the class names currently \n",
    "# 'DataFrame' 'OLS' 'Series' 'bool' 'dict' 'float' 'float64' 'int' 'method'\n",
    "# 'ndarray' 'str']\n",
    "\n",
    "fit = smf.ols(formula, data=data).fit()\n",
    "#print(dir(fit))\n",
    "\n",
    "attrs = [a for a in dir(fit) if re.match('^_.+', a) is None]\n",
    "fit_classes = []\n",
    "for a in attrs:\n",
    "    aval = getattr(fit, a)   \n",
    "    print(a, aval.__class__.__name__)\n",
    "    fit_classes.append(aval.__class__.__name__)\n",
    "\n",
    "fit_classes = np.unique(fit_classes)\n",
    "print(fit_classes) # These are the cases to deal with\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HC0_se', 'HC1_se', 'HC2_se', 'HC3_se', '_HCCM', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_cache', '_data_attr', '_get_robustcov_results', '_is_nested', '_wexog_singular_values', 'aic', 'bic', 'bse', 'centered_tss', 'compare_f_test', 'compare_lm_test', 'compare_lr_test', 'condition_number', 'conf_int', 'conf_int_el', 'cov_HC0', 'cov_HC1', 'cov_HC2', 'cov_HC3', 'cov_kwds', 'cov_params', 'cov_type', 'df_model', 'df_resid', 'eigenvals', 'el_test', 'ess', 'f_pvalue', 'f_test', 'fittedvalues', 'fvalue', 'get_influence', 'get_prediction', 'get_robustcov_results', 'het_scale', 'initialize', 'k_constant', 'llf', 'load', 'model', 'mse_model', 'mse_resid', 'mse_total', 'nobs', 'normalized_cov_params', 'outlier_test', 'params', 'predict', 'pvalues', 'remove_data', 'resid', 'resid_pearson', 'rsquared', 'rsquared_adj', 'save', 'scale', 'ssr', 'summary', 'summary2', 't_test', 'tvalues', 'uncentered_tss', 'use_t', 'wald_test', 'wald_test_terms', 'wresid']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "coefs not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-606c6b5aaa60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' not found'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: coefs not found"
     ]
    }
   ],
   "source": [
    "# Suppose we wanted to build a data type to hold these values.\n",
    "fetch_these = ['coefs', 'bse', 'conf_int', 'aic']\n",
    "\n",
    "# We need to know name, dtype, and shape of each one\n",
    "# \n",
    "for i,f in enumerate(fetch_these):\n",
    "    if hasattr(fit, f):\n",
    "        print(f)\n",
    "        attr = getattr(fit,f)        \n",
    "        if hasattr(attr, 'dtype'):\n",
    "            # for numpy arrays# \n",
    "            print(attr.ndim)\n",
    "            print(attr.shape)\n",
    "            print(attr.dtype)\n",
    "        if hasattr(attr, 'values'):\n",
    "            # for pandas Series and Dataframes \n",
    "            #print('dtype', attr.dtype)\n",
    "            print(attr.values.shape)\n",
    "            print(attr.values.dtype)\n",
    "        elif callable(attr):\n",
    "            # for callable methods\n",
    "            vals = eval('fit.' + attr.__name__ + '()')\n",
    "            #pdb.set_trace()\n",
    "            print(vals.values.shape)\n",
    "            print(vals.values.dtype)\n",
    "        else:\n",
    "            # or die\n",
    "            print(attr.__class__)\n",
    "            print(dir(attr))\n",
    "            msg = 'I dont know what to do with ' + attr\n",
    "            raise TypeError(msg)\n",
    "    else:\n",
    "        msg = f + ' not found'\n",
    "        print(dir(fit))\n",
    "        raise ValueError(msg)\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Option 2: array of fit_coef_dt, where each one holds the\n",
    "# parameter values for a single coef\n",
    "fit_arry = np.ndarray(shape=(len(rhs_di.column_names)),\n",
    "                   dtype=fit_coef_dt)\n",
    "\n",
    "# since each item in the array has the same dtype we \n",
    "# can slice *across* the fields by name\n",
    "print('value of coef for coefs: ' + ' '.join(rhs_di.column_names))\n",
    "print(fit_arry['coef']) # value of coef for all the coefs\n",
    "print()\n",
    "\n",
    "# Disadvantage: we have access to a given parameter by index, to use names we have to lookup the index\n",
    "for name,jdx in rhs_di.column_name_indexes.items():\n",
    "    if name == 'x0':\n",
    "        print('parameter: ', name, 'column index: ', jdx)\n",
    "        print('ci: ', fit_arry[jdx]['ci']) # all the info about "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
